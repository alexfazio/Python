{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexfazio/Python/blob/main/whisper-vid-2-subs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Bilingual Subtitles With Whisper**\n",
        "\n",
        "https://github.com/alexfazio/whisper-vid2subtitles"
      ],
      "metadata": {
        "id": "KqY3JOBiSHzA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hvo8QWN-a9"
      },
      "source": [
        "# Install Requirements\n",
        "\n",
        "\n",
        "The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsJUxc0aRsAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0405641f-3ab4-4cd2-a31e-3861698bdc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q pytube transformers sentencepiece tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Check Type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ],
      "metadata": {
        "id": "uk6Hn-_T_6L1",
        "outputId": "641e50c8-b5f7-43e2-c8b1-320676de203a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15101 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcribe the Video"
      ],
      "metadata": {
        "id": "5guXDmlu2Rxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import whisper\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "\n",
        "\n",
        "#@markdown If `video_path` is a YouTube link, the video will be downloaded at the `save_path`.\n",
        "video_path = 'filepath.mp4' #@param {type: 'string'}\n",
        "#@markdown Choose a Whisper model. `base` is the fastest and uses the least amount of memory.\n",
        "model_type = 'small'  #@param [\"base\", \"small\", \"medium\", \"large\"]\n",
        "#@markdown Video Language Code\n",
        "video_lang = 'en'   #@param {type: 'string'}\n",
        "#@markdown Where to save the video and subtitle.\n",
        "save_path = 'data'  #@param {type: 'string'}\n",
        "save_path = Path(save_path)\n",
        "save_path.mkdir(exist_ok=True, parents=True)\n",
        "#@markdown What to name the saved video and subtitle.\n",
        "filename = 'demo' #@param {type: 'string'}\n",
        "#@markdown Which format to save the subtitle in.\n",
        "format = 'srt' #@param [\"srt\", \"txt\"]\n",
        "\n",
        "\n",
        "\n",
        "def get_video_from_youtube_url(url, save_path=None, filename=None):\n",
        "    yt = YouTube(url)\n",
        "    video_file = str(save_path/f'{filename}.mp4')\n",
        "    s = (yt.streams.filter(progressive=True, file_extension='mp4')\n",
        "         .order_by('resolution').desc().first()\n",
        "    )\n",
        "    s.download(filename=video_file)\n",
        "    return video_file\n",
        "\n",
        "\n",
        "def transcribe(video, save_path, filename, model_type='small'):\n",
        "    if video.startswith('http'):\n",
        "        print(\"Downloading Youtube Video\\n\")\n",
        "        video = get_video_from_youtube_url(video, save_path=save_path, filename=filename\n",
        "        )\n",
        "    options = whisper.DecodingOptions(fp16=False, language=video_lang)\n",
        "    model = whisper.load_model(model_type)\n",
        "    result = model.transcribe(video, **options.__dict__, verbose=False)\n",
        "    return result, video\n",
        "\n",
        "\n",
        "def segments_to_srt(segs):\n",
        "    text = []\n",
        "    for i,s in tqdm(enumerate(segs)):\n",
        "        text.append(str(i+1))\n",
        "\n",
        "        time_start = s['start']\n",
        "        hours, minutes, seconds = int(time_start/3600), (time_start/60) % 60, (time_start) % 60\n",
        "        timestamp_start = \"%02d:%02d:%06.3f\" % (hours, minutes, seconds)\n",
        "        timestamp_start = timestamp_start.replace('.',',')\n",
        "        time_end = s['end']\n",
        "        hours, minutes, seconds = int(time_end/3600), (time_end/60) % 60, (time_end) % 60\n",
        "        timestamp_end = \"%02d:%02d:%06.3f\" % (hours, minutes, seconds)\n",
        "        timestamp_end = timestamp_end.replace('.',',')\n",
        "        text.append(timestamp_start + \" --> \" + timestamp_end)\n",
        "\n",
        "        text.append(s['text'].strip() + \"\\n\")\n",
        "\n",
        "    return \"\\n\".join(text)\n",
        "\n",
        "\n",
        "def convert_to_subtitle(segs):\n",
        "    if format == 'srt':\n",
        "        sub = segments_to_srt(segs)\n",
        "    elif format == 'txt':\n",
        "        sub = transcribed_text(segs)\n",
        "    else:\n",
        "        raise ValueError(f\"format {format} is not supported!\")\n",
        "    return sub\n",
        "\n",
        "\n",
        "def save_subtitle(sub, save_path, filename, format='srt'):\n",
        "    srt_file = save_path/f'{filename}.{format}'\n",
        "    with open(srt_file, 'w') as f:\n",
        "        f.write(sub)\n",
        "    return srt_file\n",
        "\n",
        "\n",
        "def transcribed_text(segs):\n",
        "    texts = [s['text'] for s in segs]\n",
        "    text = '\\n'.join(texts)\n",
        "    return text\n",
        "\n",
        "\n",
        "print(\"Loading the model\")\n",
        "model = whisper.load_model(f'{model_type}')\n",
        "print(\"Transcribing\")\n",
        "result, video = transcribe(video_path, save_path, filename, model_type=model_type)\n",
        "sub = convert_to_subtitle(result['segments'])\n",
        "sub_transcribed = save_subtitle(sub, save_path, filename+'-sub', format=format)\n",
        "print(f\"\\n\\nsubtitle is saved at {sub_transcribed}\")"
      ],
      "metadata": {
        "id": "hWgLFn4U2T2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73a2597-0a98-4015-8e95-20e717de1c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:20<00:00, 23.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2962/2962 [00:03<00:00, 890.78frames/s]\n",
            "4it [00:00, 33756.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "subtitle is saved at data/demo-sub.srt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}